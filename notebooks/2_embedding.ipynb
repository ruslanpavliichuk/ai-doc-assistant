{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embedding with Gemini",
   "id": "e55622954a0a667a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Embedding are numerical representations of concepts converted to number sequences, which make it easy for computers to understand the relationships between those concepts. Embedding are useful for working with NL and code, because they can be readily consumed and compared by other ML models and algorithms like clustering or search.",
   "id": "56affdfebd5cc214"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup",
   "id": "703743e201eb39a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T13:55:45.403006Z",
     "start_time": "2025-10-04T13:55:45.266021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv('../.env.local')\n",
    "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "print(\"✅ Gemini API configured\")"
   ],
   "id": "688e9ac37827546",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini API configured\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Single Embedding",
   "id": "5f8e4c1aa2d0eb65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T13:56:53.251598Z",
     "start_time": "2025-10-04T13:56:52.749882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=\"What is the capital of France?\"\n",
    ")\n",
    "\n",
    "embedding = result[\"embedding\"]\n",
    "print(f\"Embedding dimension: {len(embedding)}\")\n",
    "print(f\"First 10 values: {embedding[:10]}\")"
   ],
   "id": "c97540fb6967e434",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 768\n",
      "First 10 values: [-0.023838477, -0.008524507, 0.010140137, -0.036359083, 0.005881804, 0.017632408, 0.03440266, -0.022488268, -0.03767718, 0.090126775]\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Batch Embeddings",
   "id": "f6ee4e8784bea3aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T13:57:08.768415Z",
     "start_time": "2025-10-04T13:57:07.846223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 3: Batch embeddings\n",
    "texts = [\n",
    "    \"Python is a programming language\",\n",
    "    \"Machine learning is a subset of AI\",\n",
    "    \"Paris is the capital of France\"\n",
    "]\n",
    "\n",
    "embeddings = []\n",
    "for text in texts:\n",
    "    result = genai.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        content=text\n",
    "    )\n",
    "    embeddings.append(result['embedding'])\n",
    "\n",
    "print(f\"Created {len(embeddings)} embeddings\")\n",
    "print(f\"Each embedding has {len(embeddings[0])} dimensions\")"
   ],
   "id": "9c853dcce7a3b66e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 embeddings\n",
      "Each embedding has 768 dimensions\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calculating Similarity between texts",
   "id": "d27d188eb79a1e10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T13:59:32.797012Z",
     "start_time": "2025-10-04T13:59:32.782032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Compare first two texts\n",
    "sim = cosine_similarity(embeddings[0], embeddings[1])\n",
    "print(f\"Similarity between text 1 and 2: {sim:.4f}\")\n",
    "\n",
    "# Compare all pairs\n",
    "for i in range(len(texts)):\n",
    "    for j in range(i+1, len(texts)):\n",
    "        sim = cosine_similarity(embeddings[i], embeddings[j])\n",
    "        print(f\"\\n'{texts[i][:30]}...' \\nvs \\n'{texts[j][:30]}...'\\nSimilarity: {sim:.4f}\")"
   ],
   "id": "2f571cd54d5f927d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between text 1 and 2: 0.4605\n",
      "\n",
      "'Python is a programming langua...' \n",
      "vs \n",
      "'Machine learning is a subset o...'\n",
      "Similarity: 0.4605\n",
      "\n",
      "'Python is a programming langua...' \n",
      "vs \n",
      "'Paris is the capital of France...'\n",
      "Similarity: 0.3913\n",
      "\n",
      "'Machine learning is a subset o...' \n",
      "vs \n",
      "'Paris is the capital of France...'\n",
      "Similarity: 0.2628\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Different task types",
   "id": "2d937e10d05506da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T13:59:33.086784Z",
     "start_time": "2025-10-04T13:59:32.808168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=\"What is Python?\",\n",
    "    task_type=\"retrieval_query\"  # or \"retrieval_document\", \"semantic_similarity\"\n",
    ")\n",
    "\n",
    "print(f\"Query embedding created: {len(result['embedding'])} dimensions\")"
   ],
   "id": "35ac73fb9c031abb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding created: 768 dimensions\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Google Gemini Embeddings\n",
    "\n",
    "## Key Points:\n",
    "- **FREE** - No cost for embeddings\n",
    "- **768 dimensions** - Smaller than OpenAI (1536)\n",
    "- **Latest model**: `text-embedding-004`\n",
    "- **Access**: Direct function call (no client needed)\n",
    "\n",
    "## Usage:\n",
    "```python\n",
    "result = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=\"your text here\"\n",
    ")\n",
    "embedding = result['embedding']"
   ],
   "id": "a5b42b102412672a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
